{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:53.639846436Z",
     "start_time": "2023-12-09T11:45:53.145335306Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import struct\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "directory_path_original = './logs/dut0_original/logs_client'\n",
    "directory_path_ecc_bypass = './logs/dut0_ecc_bypass/logs_client'\n",
    "directory_path_iv_tee = './logs/dut0_iv_tee/logs_client'\n",
    "file_pattern = 'Client_dut*'\n",
    "\n",
    "# Use glob to find all files matching the pattern\n",
    "file_paths_original = glob.glob(os.path.join(directory_path_original, file_pattern))\n",
    "file_paths_ecc_bypass = glob.glob(os.path.join(directory_path_ecc_bypass, file_pattern))\n",
    "file_paths_iv_tee = glob.glob(os.path.join(directory_path_iv_tee, file_pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the frame_id_formatting\n",
    "\n",
    "Create the dictionary that holds the frame formatting for a given frame ID. This will be custom to your specific frame. Find the documentation for each field in payload_parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:53.801612735Z",
     "start_time": "2023-12-09T11:45:53.758064832Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "frame_id_formatting = {\n",
    "    \"BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\": 0,  # test frame\n",
    "    \"IIIIIIIIIIIIIII\": 1,  # fini\n",
    "    \"IIIIII\": 16,  # exception\n",
    "}\n",
    "\n",
    "keys = ['timestamp', 'total_errors', 'mcycle', 'minstret', 'imem_se', 'imem_de', 'dmem_se', 'dmem_de', 'regfile_se', 'regfile_de', 'iv', 'jump', 'branch', 'dsp_t', 'trap', 'illegal']\n",
    "# keys = ['timestamp', 'cy_c', 'tm_c', 'ir_c', 'wait_ii', 'wait_if', 'wait_mc', 'load', 'store', 'wait_ls', 'branch', 'tbranch', 'imem_ecc', 'dmem_ecc', 'regfile', 'iv']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursively checking all the log files and sorting on Unix timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_files(file_paths):\n",
    "    frames = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for json_line in file:\n",
    "                # Parse frame\n",
    "                try:\n",
    "                    frame = json.loads(json_line)\n",
    "                except Exception as error:\n",
    "                    print(f\"Failed decoding JSON for file {file_path}: {error}\")\n",
    "                frames.append(frame)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:53.727645612Z",
     "start_time": "2023-12-09T11:45:53.681955271Z"
    }
   },
   "outputs": [],
   "source": [
    "frames_original = sorted(parse_files(file_paths_original), key=lambda x: x[\"timestamp\"])\n",
    "frames_ecc_bypass = sorted(parse_files(file_paths_ecc_bypass), key=lambda x: x[\"timestamp\"])\n",
    "frames_iv_tee = sorted(parse_files(file_paths_iv_tee), key=lambda x: x[\"timestamp\"])\n",
    "df_original = pd.DataFrame(frames_original)\n",
    "df_ecc_bypass = pd.DataFrame(frames_ecc_bypass)\n",
    "df_iv_tee = pd.DataFrame(frames_iv_tee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Unix timestamp to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:54.062398608Z",
     "start_time": "2023-12-09T11:45:53.801480586Z"
    }
   },
   "outputs": [],
   "source": [
    "# def convert_unix_to_utc(pd):\n",
    "#     crc_errors = 0\n",
    "#     frame_parsing_errors = 0\n",
    "#     for frame in frames:\n",
    "#         frame['timestamp'] = str(datetime.utcfromtimestamp(float(frame['timestamp'])).replace(tzinfo=timezone.utc).strftime('%Y-%m-%d %H:%M:%S.%f UTC'))\n",
    "#         if 'data' in frame:\n",
    "#             try:\n",
    "#                 decoded_frame = decode_frame(bytes.fromhex(frame['data']))\n",
    "#                 #CRC check failed\n",
    "#                 if decoded_frame == None:\n",
    "#                     converted_frames.append({'timestamp': frame['timestamp'], 'error': \"CRC check error\"})\n",
    "#                     crc_errors += 1\n",
    "#                 # Exception\n",
    "#                 elif len(decoded_frame) < 15:\n",
    "#                     converted_frames.append({'timestamp': frame['timestamp'], 'error': f\"Frame parsing error. Data field too small: {decode_frame}\"})\n",
    "#                 # Data correct\n",
    "#                 else:\n",
    "#                     frame['data'] = decoded_frame\n",
    "#                     converted_frames.append(frame)\n",
    "#             except Exception as error:\n",
    "#                 frame_parsing_errors += 1\n",
    "#                 converted_frames.append({'timestamp': frame['timestamp'], 'error': \"Frame parsing error (possibly due to comm failure)\"})\n",
    "#                 #print(f\"Parsing error! {error}\")\n",
    "#         elif 'event' in frame:\n",
    "#             converted_frames.append(frame)\n",
    "#     return converted_frames, crc_errors, frame_parsing_errors\n",
    "\n",
    "df_original['timestamp'] = pd.to_datetime(df_original['timestamp'], unit='s').dt.tz_localize('UTC')\n",
    "df_ecc_bypass['timestamp'] = pd.to_datetime(df_ecc_bypass['timestamp'], unit='s').dt.tz_localize('UTC')\n",
    "df_iv_tee['timestamp'] = pd.to_datetime(df_iv_tee['timestamp'], unit='s').dt.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:54.068092465Z",
     "start_time": "2023-12-09T11:45:54.064329396Z"
    }
   },
   "outputs": [],
   "source": [
    "df_original = df_original.drop_duplicates()\n",
    "df_ecc_bypass = df_ecc_bypass.drop_duplicates()\n",
    "df_iv_tee = df_iv_tee.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the fields based on frame type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:54.156702092Z",
     "start_time": "2023-12-09T11:45:54.067249653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error! non-hexadecimal number found in fromhex() arg at position 0\n",
      "Parsing error! non-hexadecimal number found in fromhex() arg at position 0\n",
      "Parsing error! non-hexadecimal number found in fromhex() arg at position 0\n",
      "Parsing error! non-hexadecimal number found in fromhex() arg at position 0\n",
      "Parsing error! non-hexadecimal number found in fromhex() arg at position 0\n",
      "Parsing error! non-hexadecimal number found in fromhex() arg at position 0\n",
      "Parsing error! non-hexadecimal number found in fromhex() arg at position 0\n",
      "Parsing error! non-hexadecimal number found in fromhex() arg at position 0\n"
     ]
    }
   ],
   "source": [
    "from payload_parser import decode_frame \n",
    "\n",
    "def data_dict(data_hex):\n",
    "    try:\n",
    "        data_tup = decode_frame(bytes.fromhex(data_hex), frame_id_formatting)\n",
    "        return data_tup\n",
    "    except Exception as error:\n",
    "        print(f\"Parsing error! {error}\")\n",
    "        return data_hex \n",
    "    \n",
    "def parse_data(df):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Apply the function only to rows where 'data' is not empty\n",
    "    mask = df_copy['data'].notnull() & (df_copy['data'] != '')\n",
    "\n",
    "    df_copy.loc[mask, 'data'] = df_copy.loc[mask, 'data'].apply(data_dict)\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "df_parsed = parse_data(df_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the data tuple into readable fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = []\n",
    "\n",
    "for frame in df_parsed:\n",
    "    if 'data' in frame:\n",
    "        parsed_payload = (frame['timestamp'],) + frame['data']\n",
    "        mapping = {num: key for num, key in zip(keys, parsed_payload)}\n",
    "        data_frame.append(mapping)\n",
    "\n",
    "df = pd.DataFrame(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSP timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:54.204126229Z",
     "start_time": "2023-12-09T11:45:54.158361948Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dsp_t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dsp_t'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filtered \u001b[38;5;241m=\u001b[39m df_parsed[\u001b[43mdf_parsed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdsp_t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m filtered\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dsp_t'"
     ]
    }
   ],
   "source": [
    "filtered = df_parsed[df_parsed['dsp_t'] > 0]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:55.172960841Z",
     "start_time": "2023-12-09T11:45:54.201394447Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'iv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'iv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m filtered \u001b[38;5;241m=\u001b[39m df_parsed[\u001b[43mdf_parsed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m filtered\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.5/envs/data_filter/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'iv'"
     ]
    }
   ],
   "source": [
    "filtered = df_parsed[df_parsed['iv'] > 0]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV FPR higher than 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-09T11:45:55.256159424Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# df['imem_se'] = scaler.fit_transform(df[['imem_se']])\n",
    "# df['iv'] = scaler.fit_transform(df[['iv']])\n",
    "# df_no_duplicates = df.drop_duplicates(subset='iv', keep='first')\n",
    "# fpr_violation_condition = df_no_duplicates['iv'] < (0.98*df_no_duplicates['imem_se'])\n",
    "# fpr_violation_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double bit errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:55.340063661Z",
     "start_time": "2023-12-09T11:45:55.256391994Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_duplicates = df.drop_duplicates(subset='imem_de', keep='first')\n",
    "df_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:55.340616295Z",
     "start_time": "2023-12-09T11:45:55.256742326Z"
    }
   },
   "outputs": [],
   "source": [
    "fpr_violation_condition = df['iv'] > (0.98*df['imem_se'])\n",
    "# df[fpr_violation_condition]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering based on SmartFusion2 reset. Excluding DMEM and Register file because of scrubbing and overwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T11:45:55.438141676Z",
     "start_time": "2023-12-09T11:45:55.256931433Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = (df['imem_se'] < df['imem_se'].shift()-10) | (df['imem_de'] < df['imem_de'].shift()-10)\n",
    "resets = df[mask | mask.shift(-1)]\n",
    "pd.concat([df.head(1), resets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple explanations for differences between IMEM and instruction validator detections\n",
    "## Significant less detections by IV compared to IMEM\n",
    "\n",
    "## Significant more detections by IV compared to IMEM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
